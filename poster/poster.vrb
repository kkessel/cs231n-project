\frametitle{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% IMPORTANT:
%   Here is where you define your poster's layout params (widths and
%   vertical positions).
%   Feel free to add/remove more, to make your layout fit your needs
%
%   All dimensions are in cm (I think).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% centralize columns layout
\newcommand{\vstart}{58} % where the top row start vertically
\newcommand{\vstartCols}{8} % where the columns start vertically
\newcommand{\fullwidth}{81}  % this is the key to the values below
\newcommand{\colwidth}{26.5}

\newcommand{\firstcolpos}{1}
\newcommand{\secondcolpos}{28.75}
\newcommand{\thirdcolpos}{56.5}
\newcommand{\bottomblockstart}{108.5}


% this will add some padding to the blocks, to avoid text reaching
% the border (looks bad)
\newenvironment{paddedBlock}[2][0.95\linewidth]
    {\begin{block}{#2}\begin{minipage}{#1}}
    {\end{minipage}\end{block}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% And now ... the content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%% LEFT COLUMN
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{textblock}{\colwidth}(\firstcolpos,\vstartCols)

\begin{paddedBlock}{Summary}
Deep Neural Networks are very useful at classifying tasks but their intrinsic complexity makes it really hard to explain the reasoning behind a classification outcome. In recent work [2], statistical methods were introduced to help assess the influence of human intelligible concepts in classification outcomes.
We aim to asses and extend such methods by leveraging formal methods for Neural Network verification.
\begin{itemize}
\item \textbf{Problem:} Why did the network classify image $\mathcal{i}$ with label $k$?
\item \textbf{Solution:} Come up with classes TCAV etc bla bla? or more like we tried to test the TCAV method??
\item \textbf{Preliminary Results:} nothing nothing nothing.
\end{itemize}
\end{paddedBlock}

\begin{paddedBlock}{Talk about TCAV ?}
\underline{Input}:
\begin{itemize}
\item adjacency matrices $A_L$ and $A_U$ for the two sets of nodes;
\item features vectors $X_L$ and $X_U$;
\item labels $y_L$
\end{itemize}
\begin{figure}
    \centering
    %\missingfigure[width=0.5\textwidth]{2 graphs fig}
    %\missingfigure{figure with the two graphs (one labeled and one not) goes here}
    \includegraphics[width=0.90\textwidth]{img/graph_prob.pdf}
    %\caption{Caption}
    \label{fig:coins}
\end{figure}
\underline{Output}:
\begin{itemize}
	\item predictions for the unlabelled nodes $\hat{y}_L$
\end{itemize}
%\vspace{-5mm}
\end{paddedBlock}

\begin{paddedBlock}{Neural Network Verification}
\texttt{GCN} [1] for node classification: $\hat{y} = h(Ah(AXW_1)W_2)$
\begin{figure}
    \centering
    %\missingfigure[width=0.5\textwidth]{2 graphs fig}
    %\missingfigure{architecture of the baseline model}
    \includegraphics[width=.8\textwidth]{img/model_small.pdf}
    %\caption{Caption}
    \label{fig:small}
\end{figure}
\end{paddedBlock}
\end{textblock}

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%% RIGHT COLUMN
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{textblock}{\colwidth}(\secondcolpos,\vstartCols)
\begin{paddedBlock}{Approach: TCAV + Verification}
%\vspace{8mm}

\alert{Three-step process}
  \begin{itemize}
    \item learn low-dimensional node embeddings to encode node similarity (\texttt{VGAE} [2])
    \item hallucinate edges and complete the adjacency matrix (edges)
    \item run a \texttt{GCN} with the completed adjacency to predict node labels
  \end{itemize}


\begin{figure}%
    \centering
    \subfloat[label 1]{{\includegraphics[width=5cm]{img/mnist_bw.png} }}%
    \qquad
    \subfloat[label 2]{{\includegraphics[width=5cm]{img/mnist_color.png} }}%
    \caption{2 Figures side by side}%
    \label{fig:example}%
\end{figure}

%\vspace{8mm}

\alert{1. Link prediction - Variational Graph Auto-Encoder (\texttt{VGAE}):}
\begin{itemize}
  \item $Z\sim\mathcal{N}(\mu_Z,\sigma_Z^2)\ \ \mathrm{and}\ \ \tilde{A}=\sigma(ZZ^T).$
  \item with $\mu_Z,\sigma_Z=\mathrm{GCN}(A, X)$
\end{itemize}
\begin{align*}
\mathcal{L}_{LP}=&-\mathbb{E}_{Z\sim q(Z|A,X)}[A_{ij}\mathrm{log}\tilde{A}_{ij}+(1-A_{ij})\mathrm{log}(1-\tilde{A}_{i,j})]\\
&+\mathrm{KL}(q(Z|A,X)||p(Z)).
\end{align*}
%\vspace{-8mm}
\begin{figure}
    \centering
    %\missingfigure[width=0.5\textwidth]{2 graphs fig}
    %\missingfigure{Hallucigraph architecture sketch}
    \includegraphics[width=.8\textwidth]{img/model_big.pdf}
    %\caption{Caption}
    \label{fig:big}
\end{figure}
%\vspace{8mm}
\alert{2. Edge hallucination}
  produces $\hat{A}$:
  \begin{itemize}
    \item top$K$ ($K$ hyper-parameter)
    \item sampling using gumbel softmax [4] trick (allows gradients to flow)
  \end{itemize}
\alert{3. Node classification}
\begin{itemize}
	\item $\hat{y} = \mathrm{GCN}(\hat{A}, X)$
\end{itemize}

\end{paddedBlock}
%\vspace{3mm}
\end{textblock}


\begin{textblock}{\colwidth}(\thirdcolpos,\vstartCols)

%\begin{paddedBlock}

%\
%$\hat{y}=\mathrm{GCN}(\hat{A}, X)$

%\end{paddedBlock}

\begin{paddedBlock}{Results}
%\vspace{8mm}

\alert{Classification performance per number of hallucinated edges (cora)}
  \begin{figure}
      \centering
      %\missingfigure[width=0.5\textwidth]{2 graphs fig}
      %\missingfigure{Edge inference ROC curve}
      \includegraphics[width=.8\textwidth]{img/acc_vs_topk.png}
      %\caption{Caption}
      \label{fig:coins}
  \end{figure}

%\vspace{8mm}
\alert{Node classification results}

\begin{table}
\centering
\begin{tabular}{lcccc}
\hline

\textbf{model} &  \textbf{balanced} &   \textbf{blue 2} &    \textbf{red 2} &  \textbf{green 2} \\ \hline
\texttt{balanced\_5x50} &    $0.942$ &  $0.942$ &  $0.941$ &  $0.944$ \\
\texttt{blue2\_5x50} &    $0.780$ &  $0.952$ &  $0.682$ &  $0.689$ \\
\texttt{balanced\_3x50} &    $0.942$ &  $0.940$ &  $0.942$ &  $0.941$ \\
\texttt{blue2\_3x50} &    $0.724$ &  $0.954$ &  $0.675$ &  $0.684$ \\
\texttt{balanced\_3x20} &    $0.890$ &  $0.890$ &  $0.891$ &  $0.888$ \\
\texttt{blue2\_3x20} &    $0.708$ &  $0.923$ &  $0.663$ &  $0.672$ \\
\hline

\end{tabular}
\caption{Accuracies for various models and datasets. The \texttt{balanced\_DxW} models are trained on a color-balanced dataset, and the \texttt{blue2\_DxW} models are trained on a color-biased dataset where all $2$'s are blue, as shown in Fig~\ref{fig:dataset_biased}. Columns indicate validation datasets which are balanced or have a blue, green, or red bias on class $2$, respectively. }
\label{table:accuracies}
\end{table}



\begin{itemize}
  \item As shown in [1], the GCN improves on standalone MLP by leveraging the connections between nodes
  \item By adding "hallucinated" edges, we improve the connectivity structure, and we obtain more predictive power
\end{itemize}

\end{paddedBlock}


\begin{paddedBlock}{References}
\footnotesize{[1] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer. Reluplex: An efficient smt solver for verifying deep neural networks. In International Conference on Computer Aided Verification, pages 97â€“117. Springer, 2017}

\footnotesize{[2] B. Kim, M. Wattenberg, J. Gilmer, C. J. Cai, J. Wexler, F. B. Viegas, and R. Sayres. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In ICML, 2018}

\footnotesize{[3] Y. LeCun, C. Cortes, and C. Burges. Mnist handwritten digit database. AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist, 2:18, 2010}

\footnotesize{[4] C. Liu, T. Arnon, C. Lazarus, C. Barrett, and M. J. Kochenderfer. Algorithms for verifying deep neural networks. CoRR, abs/1903.06758, 2019}

\end{paddedBlock}
\end{textblock}


%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%% BOTTOM ROW
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{textblock}{\fullwidth}(2,\bottomblockstart)
%\begin{paddedBlock}[0.98\linewidth]{Acknowledgements}

%In case you need it, you can do this too

%\end{paddedBlock}
%\end{textblock}

